{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.utils import _pair\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for ConvLSTM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvRNNCellBase(nn.Module):\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = '{name}({input_size}, {hidden_size}'\n",
    "        if 'bias' in self.__dict__ and self.bias is not True:\n",
    "            s += ', bias={bias}'\n",
    "        if 'nonlinearity' in self.__dict__ and self.nonlinearity != \"tanh\":\n",
    "            s += ', nonlinearity={nonlinearity}'\n",
    "        s += ')'\n",
    "        return s.format(name=self.__class__.__name__, **self.__dict__)\n",
    "    \n",
    "def ConvLSTM2dCellFn(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None, in_stride=(1,1), hid_stride=(1,1), in_padding=0, hid_padding=0, in_dilation=(1,1), hid_dilation=(1,1)):\n",
    "\n",
    "    hx, cx = hidden\n",
    "    #print(F.conv2d(input, w_ih, b_ih, in_stride, in_padding, in_dilation).size(), F.conv2d(hx, w_hh, b_hh, hid_stride, hid_padding, hid_dilation).size() )\n",
    "    gates = F.conv2d(input, w_ih, b_ih, in_stride, in_padding, in_dilation) + F.conv2d(hx, w_hh, b_hh, hid_stride, hid_padding, hid_dilation)\n",
    "    \n",
    "    ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "    \n",
    "    ingate = F.sigmoid(ingate)\n",
    "    forgetgate = F.sigmoid(forgetgate)\n",
    "    cellgate = F.tanh(cellgate)\n",
    "    outgate = F.sigmoid(outgate)\n",
    "    \n",
    "    #print(ingate.size(), forgetgate.size(), cellgate.size(), outgate.size(), cx.size())\n",
    "    \n",
    "    cy = (forgetgate * cx) + (ingate * cellgate)\n",
    "    hy = outgate * F.tanh(cy)\n",
    "\n",
    "    return hy, cy\n",
    "\n",
    "class ConvLSTM2dCell(ConvRNNCellBase):\n",
    "    \"\"\"A long short-term memory (LSTM) cell.\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\begin{array}{ll}\n",
    "        i = \\mathrm{sigmoid}(W_{ii} \\star x + b_{ii} + W_{hi} \\star h + b_{hi}) \\\\\n",
    "        f = \\mathrm{sigmoid}(W_{if} \\star x + b_{if} + W_{hf} \\star h + b_{hf}) \\\\\n",
    "        g = \\tanh(W_{ig} \\star x + b_{ig} + W_{hc} h + b_{hg}) \\\\\n",
    "        o = \\mathrm{sigmoid}(W_{io} \\star x + b_{io} + W_{ho} \\star h + b_{ho}) \\\\\n",
    "        c' = f * c + i * g \\\\\n",
    "        h' = o * \\tanh(c_t) \\\\\n",
    "        \\end{array}\n",
    "\n",
    "        where \\star denotes the convolution operator\n",
    "\n",
    "        Args:\n",
    "        input_channels (int): Number of channels in the input  \n",
    "        hidden_channels (int): Number of channels in the hidden state\n",
    "        in_kernel_size (int or tuple): Size of the convolving kernel for the input, must be odd\n",
    "        hid_kernel_size (int or tuple): Size of the convolving kernel for the hidden state, must be odd\n",
    "        in_stride (int or tuple, optional): Stride of the input convolution, Default: 1\n",
    "        hid_stride (int or tuple, optional): Stride of the hidden convolution, Default: 1\n",
    "        in_dilation (int or tuple, optional): Spacing between input convolving kernel elements, Default: 1\n",
    "        hid_dilation (int or tuple, optional): Spacing between hidden convolving kernal elements, Default: 1\n",
    "        bias (bool, optional): If `False`, then the layer does not use bias weights `b_ih` and `b_hh`. Default: True\n",
    "\n",
    "    Inputs: input, (h_0, c_0)\n",
    "        - **input** (batch, in_channels, C_in, H_in): tensor containing input features\n",
    "        - **h_0** (batch, hidden_channels, C_in, H_in): tensor containing the initial hidden state for each element in the batch.\n",
    "        - **c_0** (batch, hidden_channels, C_in, H_in): tensor containing the initial cell state for each element in the batch.\n",
    "\n",
    "    Outputs: h_1, c_1\n",
    "        - **h_1** (batch, hidden_channels, C_in, H_in): tensor containing the next hidden state for each element in the batch\n",
    "        - **c_1** (batch, hidden_channels, C_in, H_in): tensor containing the next cell state for each element in the batch\n",
    "\n",
    "    Attributes:\n",
    "        weight_ih (Tensor): the learnable input-hidden weights, of shape (hidden_channels, in_channels, kernel_size[0], kernel_size[1])\n",
    "        weight_hh: the learnable hidden-hidden weights, of shape  (hidden_channels, in_channels, kernel_size[0], kernel_size[1])\n",
    "        bias_ih: the learnable input-hidden bias, of shape `(hidden_channels)`\n",
    "        bias_hh: the learnable hidden-hidden bias, of shape `(hidden_channels)`\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> rnn = nn.ConvLSTM2dCell(10, 20, 3)\n",
    "        >>> input = Variable(torch.randn(6, 3, 10, 12, 12))\n",
    "        >>> hx = Variable(torch.randn(3, 20, 12, 12))\n",
    "        >>> cx = Variable(torch.randn(3, 20, 12, 12))\n",
    "        >>> output = []\n",
    "        >>> for i in range(6):\n",
    "        ...     hx, cx = rnn(input[i], (hx, cx))\n",
    "        ...     output.append(hx)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, in_kernel_size, hid_kernel_size, in_stride=1, hid_stride=1, in_dilation=1, hid_dilation=1, bias=True):\n",
    "        super(ConvLSTM2dCell, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "#         self.im_rows, self.im_cols = im_size\n",
    "#         self.batch_size = batch_size\n",
    "        self.in_kernel_size = _pair(in_kernel_size)\n",
    "        \n",
    "        if isinstance(in_kernel_size, int):\n",
    "            self.in_padding = ((in_kernel_size-1)/2, (in_kernel_size-1)/2)\n",
    "        else:\n",
    "            self.in_padding = ((in_kernel_size[0]-1)/2, (in_kernel_size[1]-1)/2)\n",
    "            \n",
    "        if isinstance(hid_kernel_size, int):\n",
    "            self.hid_padding = ((hid_kernel_size-1)/2, (hid_kernel_size-1)/2)\n",
    "        else:\n",
    "            self.hid_padding = ((hid_kernel_size[0]-1)/2, (hid_kernel_size[1]-1)/2)\n",
    "            \n",
    "        self.hid_kernel_size = _pair(hid_kernel_size)\n",
    "        self.in_stride = _pair(in_stride)\n",
    "        self.hid_stride = _pair(hid_stride)\n",
    "        self.in_dilation = _pair(in_dilation)\n",
    "        self.hid_dilation = _pair(hid_dilation)\n",
    "        self.bias = bias\n",
    "\n",
    "        self.weight_ih = Parameter(torch.Tensor(4 * self.hidden_channels, self.in_channels, *self.in_kernel_size))\n",
    "        self.weight_hh = Parameter(torch.Tensor(4 * self.hidden_channels, self.hidden_channels, *self.hid_kernel_size))\n",
    "\n",
    "        if bias:\n",
    "            self.bias_ih = Parameter(torch.Tensor(4 * self.hidden_channels))\n",
    "            self.bias_hh = Parameter(torch.Tensor(4 * self.hidden_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias_ih', None)\n",
    "            self.register_parameter('bias_hh', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        n = self.in_channels\n",
    "        for k in self.hid_kernel_size:\n",
    "            n *= k\n",
    "        stdv = 1. /math.sqrt(n)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "            \n",
    "    def init_hidden(self, batch_size, im_size):\n",
    "        im_rows, im_cols = im_size\n",
    "        return Variable(torch.zeros(batch_size, self.hidden_channels, im_rows, im_cols)), Variable(torch.zeros(batch_size, self.hidden_channels, im_rows, im_cols))\n",
    "        \n",
    "\n",
    "    def forward(self, input, hx):\n",
    "        return ConvLSTM2dCellFn(\n",
    "            input, hx,\n",
    "            self.weight_ih, self.weight_hh,\n",
    "            self.bias_ih, self.bias_hh,\n",
    "            self.in_stride, self.hid_stride,\n",
    "            self.in_padding, self.hid_padding,\n",
    "            self.in_dilation, self.hid_dilation\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes for building convLSTM\n",
    "For input args, we should give number of input and hidden layer channels. It will infer the number of rows and columns from the input that is given. We also need to give number of strides etc just like the conv2d layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doesn't allow:\n",
    "1. Groups\n",
    "2. Multiple layers \n",
    "3. Conv transpose (hence, no output_padding)\n",
    "4. bidirectional\n",
    "5. Custom activation functions\n",
    "\n",
    "### Other specifications:\n",
    "1. Kernel size for the input and the recurrent convolutions are the same\n",
    "\n",
    "### Remember to:\n",
    "1. Make the kernel size a tuple\n",
    "2. Remove the redundant _all_weights thing because there is only one layer\n",
    "3. Change the reset_parameters. Not sure what the right init should be when we have conv filter like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing ConvLSTM2dCell \n",
    "\n",
    "Testing the ConvLSTM Cell for known weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,0 ,.,.) = \n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       " \n",
       " (0 ,3 ,.,.) = \n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       " \n",
       " (0 ,4 ,.,.) = \n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       "   0.7616  0.7616  0.7616  0.7616\n",
       " [torch.cuda.FloatTensor of size 1x5x4x4 (GPU 0)], Variable containing:\n",
       " (0 ,0 ,.,.) = \n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       " \n",
       " (0 ,3 ,.,.) = \n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       " \n",
       " (0 ,4 ,.,.) = \n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       "   1  1  1  1\n",
       " [torch.cuda.FloatTensor of size 1x5x4x4 (GPU 0)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.Tensor([3, 4, 4])\n",
    "input = input.cuda()\n",
    "\n",
    "convlstm = ConvLSTM2dCell(3, 5, 3, 3, in_stride=1, hid_stride=1, in_dilation=1, hid_dilation=1, bias=False)\n",
    "\n",
    "convlstm.cuda()\n",
    "\n",
    "hidden = convlstm.init_hidden(1, (4, 4))\n",
    "hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
    "\n",
    "list(convlstm.parameters())[0].data[:5] = torch.zeros(5, 3, 3, 3)\n",
    "list(convlstm.parameters())[0].data[5:10] = torch.ones(5, 3, 3, 3)\n",
    "list(convlstm.parameters())[0].data[10:15] = 2*torch.ones(5, 3, 3, 3)\n",
    "list(convlstm.parameters())[0].data[15:] = 3*torch.ones(5, 3, 3, 3)\n",
    "list(convlstm.parameters())[1].data[:5] = torch.zeros(5, 5, 3, 3)\n",
    "list(convlstm.parameters())[1].data[5:10] = torch.ones(5, 5, 3, 3)\n",
    "list(convlstm.parameters())[1].data[10:15] = 2*torch.ones(5, 5, 3, 3)\n",
    "list(convlstm.parameters())[1].data[15:] = 3*torch.ones(5, 5, 3, 3)\n",
    "list(convlstm.parameters())\n",
    "\n",
    "input = Variable(torch.ones(1, 3, 4, 4), requires_grad=False)\n",
    "input = input.cuda()\n",
    "hidden = convlstm.forward(input, hidden)\n",
    "convlstm.forward(input, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "\n",
       "(0 ,1 ,.,.) = \n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "\n",
       "(0 ,2 ,.,.) = \n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "\n",
       "(0 ,3 ,.,.) = \n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "\n",
       "(0 ,4 ,.,.) = \n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "  0.4621  0.4621  0.4621  0.4621\n",
       "[torch.cuda.FloatTensor of size 1x5x4x4 (GPU 0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building ConvLSTMEnc-Dec\n",
    "Replicate the network built in Keras and train on confused ball dataset\n",
    "\n",
    "### TODO:\n",
    "1. Re-write code so hidden states for each layer don't have to be initialized separately\n",
    "2. Change the optimizer\n",
    "3. Plot the loss (check what to see with every epoch) and check loss magnitude between keras and this one\n",
    "4. Weight init must be same as keras\n",
    "5. Optimizer params must be same as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvLSTMEncDec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTMEncDec, self).__init__()\n",
    "        self.convEnc1 = nn.Conv2d(1, 50, 3, padding=1)\n",
    "        self.ReLUEnc1 = nn.Threshold(0.0, 0.0)\n",
    "        self.poolEnc1 = nn.MaxPool2d(2)\n",
    "        self.convLSTM1 = ConvLSTM2dCell(50, 100, 3, 3)\n",
    "        self.convLSTM0 = ConvLSTM2dCell(101, 100, 3, 3)\n",
    "        self.deconvDec1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.convDec = nn.Conv2d(100, 1, 3, padding=1)\n",
    "        \n",
    "    def forward(self, input, R1_hidden, R0_hidden):\n",
    "        A1_conv = self.convEnc1(input)\n",
    "        A1_relu = self.ReLUEnc1(A1_conv)\n",
    "        A1 = self.poolEnc1(A1_relu)\n",
    "        R1_hidden = self.convLSTM1(A1, R1_hidden) \n",
    "        R0_input_topdown = self.deconvDec1(R1_hidden[0])\n",
    "        R0_input = torch.cat((R0_input_topdown, input), dim=1)\n",
    "        R0_hidden = self.convLSTM0(R0_input, R0_hidden)\n",
    "        output = self.convDec(R0_hidden[0])\n",
    "        return R1_hidden, R0_hidden, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hickle as hkl\n",
    "datapath = '/home/ybansal/Documents/Research/stochastic-prednet/Data/confused_ball/train.hkl'\n",
    "f = open(datapath, 'r')\n",
    "data_container = hkl.load(f)\n",
    "f.close()\n",
    "X_train = np.swapaxes(np.swapaxes(data_container['videos'][:,0:9], 3, 4), 2, 3)\n",
    "Y_train = np.swapaxes(np.swapaxes(data_container['videos'][:,1:10], 3, 4), 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = Variable(torch.from_numpy(X_train.astype(np.dtype('float32'))), requires_grad=False)\n",
    "Y_train = Variable(torch.from_numpy(Y_train.astype(np.dtype('float32'))), requires_grad=False)\n",
    "X_train = X_train.cuda()\n",
    "Y_train = Y_train.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_datapoints = X_train.size()[0]\n",
    "num_timesteps = X_train.size()[1]\n",
    "im_size = (X_train.size()[3], X_train.size()[4])\n",
    "\n",
    "num_epochs = 10 #Number of times it goes over the entire training set\n",
    "index_array = np.arange(num_datapoints)\n",
    "batch_size = 10\n",
    "num_batches = num_datapoints/batch_size\n",
    "learning_rate = 0.0005\n",
    "\n",
    "print_every = 1\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "model = ConvLSTMEncDec()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)\n",
    "\n",
    "def train(X_train_batch, Y_train_batch):\n",
    "    \n",
    "    #This part should not be separate for each hidden layer\n",
    "    R1_hidden = model.convLSTM1.init_hidden(batch_size, (im_size[0]/2, im_size[0]/2))\n",
    "    R0_hidden = model.convLSTM0.init_hidden(batch_size, im_size)\n",
    "    R1_hidden = (R1_hidden[0].cuda(), R1_hidden[1].cuda())\n",
    "    R0_hidden = (R0_hidden[0].cuda(), R0_hidden[1].cuda())\n",
    "    #print(R1_hidden[0].size(), R0_hidden[0].size())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(X_train_batch.size()[1]):\n",
    "        R1_hidden, R0_hidden, output = model(X_train_batch[:,i], R1_hidden, R0_hidden)\n",
    "        loss += criterion(output, Y_train_batch[:,i])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#     for p in model.parameters():\n",
    "#         p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.data[0] / X_train_batch.size()[0]\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    npr.shuffle(index_array)\n",
    "    \n",
    "    for b in range(num_batches):\n",
    "        X_train_batch = X_train[b*batch_size:(b+1)*batch_size]\n",
    "        Y_train_batch = Y_train[b*batch_size:(b+1)*batch_size]\n",
    "\n",
    "        output, loss = train(X_train_batch, Y_train_batch)\n",
    "        total_loss += loss\n",
    "        \n",
    "        if b % print_every == 0:\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start), b, b / num_batches * 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(X_train):\n",
    "    N = X_train.size()[0]\n",
    "    \n",
    "    predicted_frames = Variable(torch.Tensor(N, num_timesteps, 1, im_size[0], im_size[1]))\n",
    "    predicted_frames = predicted_frames.cuda()\n",
    "    \n",
    "    R1_hidden = model.convLSTM1.init_hidden(N, (im_size[0]/2, im_size[0]/2))\n",
    "    R0_hidden = model.convLSTM0.init_hidden(N, im_size)\n",
    "    \n",
    "    R1_hidden = (R1_hidden[0].cuda(), R1_hidden[1].cuda())\n",
    "    R0_hidden = (R0_hidden[0].cuda(), R0_hidden[1].cuda())\n",
    "    \n",
    "    print(R1_hidden[0].size(), R1_hidden[1].size(), R0_hidden[0].size(), R0_hidden[1].size(), X_train[:,0].size())\n",
    "\n",
    "    for i in range(X_train_batch.size()[1]):\n",
    "        R1_hidden, R0_hidden, predicted_frames[:,i] = model(X_train[:,i], R1_hidden, R0_hidden)\n",
    "        \n",
    "    return predicted_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_frames = predict(X_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=7\n",
    "\n",
    "nt = 9\n",
    "gs = gridspec.GridSpec(3, nt)\n",
    "gs.update(wspace=0., hspace=0.)\n",
    "for t in range(nt):\n",
    "        plt.subplot(gs[t])\n",
    "        plt.imshow(X_train[i,t,0,:,:].data.cpu().numpy(), interpolation='none')\n",
    "        plt.gray()\n",
    "        plt.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n",
    "        if t==0: plt.ylabel('Actual', fontsize=10)\n",
    "\n",
    "        plt.subplot(gs[t + nt])\n",
    "        plt.imshow(predicted_frames[i,t,0,:,:].data.cpu().numpy(), interpolation='none')\n",
    "        plt.gray()\n",
    "        plt.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n",
    "        if t==0: plt.ylabel('Predicted', fontsize=10)\n",
    "            \n",
    "        plt.subplot(gs[t + 2*nt])\n",
    "        plt.imshow(X_train[i,t,0, :,:].data.cpu().numpy()-predicted_frames[i,t,0,:,:].data.cpu().numpy(), interpolation='none')\n",
    "        plt.gray()\n",
    "        plt.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n",
    "        if t==0: plt.ylabel('Predicted', fontsize=10)\n",
    "            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(predicted_frames[i,6,0,:,:].data.cpu().numpy(), interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[i,5,0,:,:].data.cpu().numpy(), interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_container['trajectories'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ConvLSTMEncDec.se"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
